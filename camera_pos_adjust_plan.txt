========================================================================
项目方案：基于边缘距离场优化的 Sim-to-Real 相机外参自动对齐方案
========================================================================

1. 背景与问题描述
------------------------------------------------------------------------
目前在构建 Sim2Real（仿真到现实）的机械臂实验环境时，存在视觉反馈上的 Sim2Real Gap。

- 现状：
  1. 仿真环境（Sim）与真实环境（Real）的物理尺寸已对齐（如黑线网格位置准确）。
  2. 真实相机的内参（Intrinsics）及畸变系数已完成高精度标定。
  3. 通过视觉观察对比（Overlay视图），Sim 与 Real 的画面仍存在明显偏差。

- 问题根源：
  测量误差主要来源于相机的“外参”（Extrinsics），即物理空间中的光心位置（x, y, z）以及镜头朝向（roll, pitch, yaw）。

- 场景特征：
  环境具有极高的对比度特征（白底黑线网格），且几何结构已知。这为基于视觉的自动校准提供了完美的锚点。

2. 技术路线：基于距离变换的几何对齐
------------------------------------------------------------------------
鉴于场景为重复纹理的网格结构，传统的特征点匹配（如 SIFT/ORB）容易出现误匹配且精度受限。本方案采用“3D点云投影 + 2D距离场优化”的方法，通过最小化重投影误差来反推相机外参。

核心思想：将 Sim 环境中已知的 3D 网格线投影到 Real 图像上，通过优化相机位姿，使得投影线完美落在 Real 图像的黑线上。

3. 实施步骤
------------------------------------------------------------------------

阶段一：数据预处理
[1] 真实图像处理 (Real Domain)
    - 输入：真实相机拍摄的原始图像。
    - 步骤：
      a. 畸变校正：使用已标定的内参/畸变系数对图像进行去畸变（Undistort）。
      b. 二值化：提取黑色网格线。
      c. 细化（可选）：对线条进行骨架化提取中心线。
      d. 距离变换（Distance Transform）：生成“势能场图”。图上每个像素的值等于该点到最近黑线的欧氏距离。
         （效果：黑线上值为0，越远离黑线值越大，形成平滑的优化梯度）。

[2] 仿真数据准备 (Sim Domain)
    - 输入：仿真环境中黑线的 3D 坐标数据。
    - 格式：离散化的 3D 点云数组 (N, 3)。无需渲染图像，仅需几何坐标。

阶段二：位姿优化 (Optimization Loop)
[1] 定义优化变量
    - 待优化参数：相机 6-DoF 外参 [x, y, z, roll, pitch, yaw]。
    - 初始猜测：基于当前手工测量的粗略值。

[2] 定义损失函数 (Loss Function)
    - 输入：当前猜测的外参 pose。
    - 过程：
      a. 使用 cv2.projectPoints 将 Sim 中的 3D 网格点投影到 2D 像素坐标系。
      b. 在 Real 图像的“距离变换图”上索引这些投影坐标。
      c. 读取对应的距离值。
    - 输出：所有投影点的距离值之和（Sum of Distances）。
      （Loss = 0 意味着 Sim 的线完美重叠在 Real 的线上）。

[3] 执行优化
    - 算法选择：Nelder-Mead 或 CMA-ES（无梯度优化算法）。
    - 原因：投影过程涉及离散采样，不可直接求导，且参数量少（仅6个），该类算法收敛极快且鲁棒。

4. 伪代码逻辑 (Python reference)
------------------------------------------------------------------------
def optimize_camera_pose():
    # 1. 准备距离场 (Real)
    real_img = load_image("real_view.jpg")
    binary_grid = threshold(real_img)     # 提取黑线
    dist_map = cv2.distanceTransform(binary_grid) # 生成梯度场

    # 2. 准备 3D 点 (Sim)
    grid_points_3d = get_sim_grid_coordinates() # shape (N, 3)

    # 3. 损失函数
    def objective_func(camera_pose_6d):
        rvec, tvec = parse_pose(camera_pose_6d)
        
        # 将 Sim 的点投影到 2D 平面
        projected_points, _ = cv2.projectPoints(
            grid_points_3d, rvec, tvec, K_matrix, dist_coeffs
        )
        
        # 在距离场图中查表，计算偏差
        total_error = 0
        for p in projected_points:
            # 如果点落在最近的黑线上，dist_map[p] 为 0
            # 如果偏离，dist_map[p] 为偏离像素距离
            total_error += dist_map[int(p.y), int(p.x)]
            
        return total_error / len(projected_points)

    # 4. 开始求解
    result = scipy.optimize.minimize(
        objective_func, 
        x0=initial_guess, 
        method='Nelder-Mead'
    )
    
    return result.x  # 返回校准后的精确相机位姿

5. 预期结果与验证
------------------------------------------------------------------------
- 输出产物：一组精确的相机外参 (Position & Orientation)。
- 验证方式：将解算出的参数填回仿真器，重新渲染 Sim 视图，并与 Real 视图进行 Alpha Blending 叠加。
- 成功标准：Overlay 视图中，黑线完全重合，无重影（Double Vision）。

6. 方案优势
------------------------------------------------------------------------
1. 精度高：基于距离场的优化可实现亚像素级（Sub-pixel）对齐。
2. 鲁棒性强：避免了 SIFT 在重复纹理（网格）上匹配错误的风险。
3. 自动化：无需人工手动打点，算法自动寻找全局最优解。