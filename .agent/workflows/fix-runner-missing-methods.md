---
description: ä¿®å¤ PPORunner ä¸­æœªå®šä¹‰çš„æ–¹æ³•è°ƒç”¨
---

# ä»»åŠ¡ï¼šä¿®å¤ PPORunner æœªå®šä¹‰æ–¹æ³•

## ğŸ“‹ ä»»åŠ¡æ¦‚è¿°

`scripts/training/runner.py` ä¸­è°ƒç”¨äº† `self._flatten_obs()` å’Œ `self._normalize_obs()` æ–¹æ³•ï¼Œä½†è¿™äº›æ–¹æ³•**æœªåœ¨ç±»ä¸­å®šä¹‰**ã€‚éœ€è¦åˆ†æè¿™äº›è°ƒç”¨æ˜¯å¦å¿…è¦ï¼Œå¹¶è¿›è¡Œä¿®å¤ã€‚

## ğŸ¯ ç›®æ ‡

1. åˆ†æ wrapper é“¾æ˜¯å¦å·²å¤„ç† flatten å’Œ normalize
2. å¦‚æœ wrapper å·²å¤„ç†ï¼šåˆ é™¤å†—ä½™è°ƒç”¨
3. å¦‚æœéœ€è¦ä¿ç•™ï¼šå®ç°è¿™äº›æ–¹æ³•

---

## ğŸ“ é—®é¢˜å®šä½

### é—®é¢˜è°ƒç”¨ç‚¹

| è¡Œå· | ä»£ç  | ä¸Šä¸‹æ–‡ |
|------|------|--------|
| 445 | `next_obs = self._flatten_obs(next_obs).to(self.device)` | `train()` åˆå§‹ reset å |
| 480 | `norm_next_obs = self._normalize_obs(next_obs)` | GAE è®¡ç®—å‰ |
| 496 | `container["obs"] = self._normalize_obs(container["obs"])` | PPO update å‰ |

---

## ğŸ” åˆ†æèƒŒæ™¯

### Wrapper é“¾ç»“æ„ (ä»å¤–åˆ°å†…)

```
ManiSkillVectorEnv
  â””â”€â”€ RecordEpisode (eval only)
        â””â”€â”€ NormalizeObservationGPU (if normalize_obs=true)
              â””â”€â”€ FlattenStateWrapper  â† å·²å¤„ç† flatten
                    â””â”€â”€ FlattenActionWrapper
                          â””â”€â”€ SingleArmWrapper (lift/stack)
                                â””â”€â”€ Track1Env (BaseEnv)
```

### å…³é”®å‘ç°

1. **`FlattenStateWrapper`** (env_utils.py:266-363): 
   - åœ¨ `observation()` æ–¹æ³•ä¸­å·²å°† dict obs å±•å¹³ä¸º tensor
   - `reset()` å’Œ `step()` è‡ªåŠ¨è°ƒç”¨ `self.observation()`

2. **`NormalizeObservationGPU`** (env_utils.py:60-86):
   - åœ¨ `_normalize()` æ–¹æ³•ä¸­å·²æ ‡å‡†åŒ–è§‚æµ‹
   - `reset()` å’Œ `step()` è‡ªåŠ¨è°ƒç”¨ `self._normalize()`

### ç»“è®º

- `self._flatten_obs()`: **å†—ä½™** - FlattenStateWrapper å·²å¤„ç†
- `self._normalize_obs()`: **éœ€è¦ä¿ç•™ä½†åº”æ”¹ç”¨ wrapper** - åœ¨ rollout æœŸé—´ wrapper è‡ªåŠ¨å¤„ç†ï¼Œä½† GAE å’Œ PPO update éœ€è¦æ‰‹åŠ¨è°ƒç”¨

---

## ğŸ“ ä¿®æ”¹æ–¹æ¡ˆ

### æ–¹æ¡ˆ A: åˆ é™¤å†—ä½™è°ƒç”¨ (æ¨è)

ç”±äº wrapper å·²å¤„ç† flatten å’Œ normalizeï¼Œrollout é˜¶æ®µè¿”å›çš„ obs å·²ç»æ˜¯å±•å¹³ä¸”æ ‡å‡†åŒ–çš„ã€‚é—®é¢˜åœ¨äº:

1. **ç¬¬ 445 è¡Œ**: `reset()` è¿”å›çš„ obs å·²ç»è¿‡ wrapper å¤„ç†ï¼Œæ— éœ€å† flatten
2. **ç¬¬ 480, 496 è¡Œ**: éœ€è¦ç¡®è®¤ rollout é˜¶æ®µå­˜å‚¨çš„ obs æ˜¯å¦å·²æ ‡å‡†åŒ–

### å†³å®šå› ç´ 

æŸ¥çœ‹ `_rollout()` æ–¹æ³•:
- ç¬¬ 372 è¡Œ: `storage["obs"][step] = obs` - å­˜å‚¨å½“å‰ obs
- ç¬¬ 430 è¡Œ: `obs = next_obs` - next_obs æ¥è‡ª `_step_env()`

å¦‚æœ `NormalizeObservationGPU` wrapper åœ¨ step æ—¶è¿”å›æ ‡å‡†åŒ–çš„ obsï¼Œåˆ™ storage ä¸­çš„ obs å·²ç»æ˜¯æ ‡å‡†åŒ–çš„ï¼Œç¬¬ 496 è¡Œæ˜¯**é‡å¤æ ‡å‡†åŒ–**ï¼

---

## ğŸ“ éœ€è¦ä¿®æ”¹çš„ä»£ç 

### æ–‡ä»¶: `scripts/training/runner.py`

#### ä¿®æ”¹ç‚¹ 1: åˆ é™¤ `_flatten_obs` è°ƒç”¨ (ç¬¬ 445 è¡Œ)

**å½“å‰ä»£ç :**
```python
# Initial reset
next_obs, _ = self.envs.reset(seed=self.cfg.seed)
next_obs = self._flatten_obs(next_obs).to(self.device)
next_bootstrap_mask = torch.zeros(self.num_envs, device=self.device, dtype=torch.bool)
```

**ä¿®æ”¹å:**
```python
# Initial reset
# Note: FlattenStateWrapper already flattens obs, NormalizeObservationGPU already normalizes
next_obs, _ = self.envs.reset(seed=self.cfg.seed)
next_obs = next_obs.to(self.device) if not next_obs.device == self.device else next_obs
next_bootstrap_mask = torch.zeros(self.num_envs, device=self.device, dtype=torch.bool)
```

æˆ–è€…æ›´ç®€æ´:
```python
# Initial reset (obs already flattened and normalized by wrappers)
next_obs, _ = self.envs.reset(seed=self.cfg.seed)
# next_obs is already on GPU from ManiSkillVectorEnv
next_bootstrap_mask = torch.zeros(self.num_envs, device=self.device, dtype=torch.bool)
```

---

#### ä¿®æ”¹ç‚¹ 2: GAE è®¡ç®—å‰çš„ normalize (ç¬¬ 478-481 è¡Œ)

**å½“å‰ä»£ç :**
```python
# GAE Calculation
with torch.no_grad():
    norm_next_obs = self._normalize_obs(next_obs)
    next_value = self.get_value(norm_next_obs)
```

**åˆ†æ:**
- `next_obs` æ¥è‡ªæœ€åä¸€æ¬¡ `_step_env()`ï¼Œå·²ç»è¿‡ `NormalizeObservationGPU` å¤„ç†
- å› æ­¤ `next_obs` å·²ç»æ˜¯æ ‡å‡†åŒ–çš„ï¼

**ä¿®æ”¹å:**
```python
# GAE Calculation
# Note: next_obs is already normalized by NormalizeObservationGPU wrapper
with torch.no_grad():
    next_value = self.get_value(next_obs)
```

---

#### ä¿®æ”¹ç‚¹ 3: PPO Update å‰çš„ normalize (ç¬¬ 493-496 è¡Œ)

**å½“å‰ä»£ç :**
```python
# CRITICAL FIX: Normalize observations BEFORE flattening for PPO update
# This ensures the update phase sees the same distribution as the rollout phase
if self.normalize_obs:
    container["obs"] = self._normalize_obs(container["obs"])
```

**åˆ†æ:**
- `container["obs"]` åœ¨ `_rollout()` ç¬¬ 372 è¡Œè¢«å¡«å……
- å¡«å……çš„ `obs` æ¥è‡ªç¬¬ 370 è¡Œçš„å¾ªç¯ï¼Œåˆå§‹å€¼æ¥è‡ª `train()` ä¼ å…¥çš„ `obs`
- è¿™äº› obs å·²ç»è¿‡ wrapper å¤„ç†ï¼Œæ‰€ä»¥å·²ç»æ˜¯æ ‡å‡†åŒ–çš„ï¼

**ä¿®æ”¹å:**
```python
# Note: container["obs"] was populated during rollout with already-normalized obs
# (NormalizeObservationGPU wrapper processes observations in step/reset)
# No additional normalization needed here
```

å³ï¼š**åˆ é™¤è¿™æ•´ä¸ª if å—**

---

## âš ï¸ æ³¨æ„äº‹é¡¹

### 1. å…³äº `normalize_obs` é…ç½®

å½“å‰ä»£ç ä¸­ `self.normalize_obs` æ§åˆ¶æ˜¯å¦åº”ç”¨æ ‡å‡†åŒ–ã€‚ä¿®æ”¹å:
- `normalize_obs=True`: wrapper å¤„ç†ï¼Œæ— éœ€æ‰‹åŠ¨è°ƒç”¨
- `normalize_obs=False`: wrapper ä¸æ·»åŠ ï¼Œobs æœªæ ‡å‡†åŒ–

### 2. ç¡®è®¤ Wrapper é¡ºåº

ä¿®æ”¹å‰ç¡®è®¤ `make_env()` ä¸­ wrapper æ·»åŠ é¡ºåº:
```python
# env_utils.py make_env()
env = FlattenStateWrapper(env)  # First: flatten
# ...
if normalize_obs:
    env = NormalizeObservationGPU(env)  # After flatten
```

### 3. æµ‹è¯•éªŒè¯

ä¿®æ”¹åå¿…é¡»éªŒè¯è®­ç»ƒæ˜¯å¦æ­£å¸¸:
```bash
# å¿«é€Ÿæµ‹è¯• (10 iterations)
uv run python scripts/train.py training.total_timesteps=100000 training.num_envs=64
```

---

## âœ… éªŒæ”¶æ ‡å‡†

1. **è¯­æ³•æ­£ç¡®**:
   ```bash
   uv run python -m py_compile scripts/training/runner.py
   ```

2. **è¿è¡Œæµ‹è¯•**:
   ```bash
   uv run python -c "from scripts.training.runner import PPORunner; print('Import OK')"
   ```

3. **æ—  AttributeError**: è®­ç»ƒæ—¶ä¸å†å‡ºç° `_flatten_obs` æˆ– `_normalize_obs` æœªå®šä¹‰é”™è¯¯

---

## ğŸ“ ç›¸å…³æ–‡ä»¶è·¯å¾„

- `/home/admin/Desktop/eai-final-project/scripts/training/runner.py`
- `/home/admin/Desktop/eai-final-project/scripts/training/env_utils.py` (å‚è€ƒ)

---

## ğŸ”— å‰ç½®ä¾èµ–

- `/refactor-wrapper-traversal` åº”å·²å®Œæˆ (æä¾› `find_wrapper` å·¥å…·å‡½æ•°)

---

// turbo-all
